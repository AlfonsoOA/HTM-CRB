# Install and load necessary packages
# Make sure you have these packages installed. If not, uncomment the `install.packages()` lines.
# install.packages("tidyverse")
# install.packages("stringr")
# install.packages("pheatmap")
# install.packages("dunn.test")
# install.packages("ggpubr")
# install.packages("readxl") # Necessary to read .xls files
# install.packages("patchwork") # For combining plots

library(tidyverse)
library(stringr)
library(pheatmap)
library(dunn.test)
library(ggpubr)
library(readxl) # Load the library to read .xls
library(patchwork) # For combining plots easily

# --- GLOBAL PATHS AND LIBRARIES CONFIGURATION ---
# Define the base project path (the folder containing "ClueGO_results" and "Metaanalisis")
# ENSURE TO CHANGE THIS PATH TO YOUR COMPUTER'S PATH!
project_base_path <- "C:/Users/Alfonso/Desktop/AlfonsoOA_MSI/1Investigacion/7_Especial_IJMS/analisis27062025/"

# Path for the raw ClueGO .xls files and general analysis output (your original ClueGO_results folder)
base_analysis_path <- file.path(project_base_path, "ClueGO_results/") # Added trailing slash for consistency

# Path where the consolidated TSV files generated by this script will be saved
consolidated_tsvs_folder_path <- file.path(base_analysis_path, "consolidated_tsvs")

# Path where the final analysis results (matrices, heatmaps, boxplots) will be saved
output_results_folder_path <- file.path(base_analysis_path, "ClueGO_analysis")

# Path for the meta-analysis specific results (the requested folder)
meta_analysis_results_folder_path <- file.path(project_base_path, "Metaanalisis")


# --- 1. Global Variables and Mappings Definition ---

# List of all expected method names
# Ensure this list is exhaustive and reflects your columns in the consolidated TSVs.
all_expected_method_names <- c(
  "bayes_Bayes", "bayes_FC",
  "deqms_Bayes", "deqms_FC",
  "limma_Bayes", "limma_FC",
  "msstats_Bayes", "msstats_FC",
  "tstudent_Bayes", "tstudent_FC",
  "twelch_Bayes", "twelch_FC"
)

# Definition of Hypothesis Testing Methods (HTMs) and Criteria for Biological Relevance (CBR)
htms <- c("bayes", "deqms", "limma", "msstats", "tstudent", "twelch")
cbrs <- c("Bayes", "FC")

# Classification of methods for determining comparison type
methods_FC <- c("bayes_FC", "deqms_FC", "limma_FC", "msstats_FC", "tstudent_FC", "twelch_FC")
methods_Bayes <- c("bayes_Bayes", "deqms_Bayes", "limma_Bayes", "msstats_Bayes", "tstudent_Bayes", "twelch_Bayes")

# --- ONTOLOGY MAPPING BY WORK ---
works_ontology_map <- list(
  W1 = c("GO_BiologicalProcess-EBI-UniProt-GOA-ACAP-ARAP_02.06.2025_00h00",
         "GO_MolecularFunction-EBI-UniProt-GOA-ACAP-ARAP_02.06.2025_00h00",
         "KEGG_25.05.2022"),
  W2 = c("GO_BiologicalProcess-Custom-GOA-ACAP-ARAP_04.11.2021_00h00",
         "GO_MolecularFunction-Custom-GOA-ACAP-ARAP_04.11.2021_00h00"),
  W3 = c("GO_BiologicalProcess-Custom-GOA-ACAP-ARAP_30.05.2022_00h00",
         "GO_MolecularFunction-Custom-GOA-ACAP-ARAP_30.05.2022_00h00",
         "KEGG_30.05.2022"),
  W4 = c("GO_BiologicalProcess-Custom-GOA_24.07.2019_00h00",
         "GO_MolecularFunction-Custom-GOA_24.07.2019_00h00"),
  W5 = c("GO_BiologicalProcess-Custom-GOA_24.07.2019_00h00",
         "GO_MolecularFunction-Custom-GOA_24.07.2019_00h00")
)

# List of work names (e.g., "W1", "W2", ...)
works_list <- names(works_ontology_map)


# --- 2. Auxiliary Functions ---

# AUXILIARY FUNCTION TO EXTRACT THE BASE METHOD NAME (HTM)
get_htm_name <- function(method_name) {
  str_split(method_name, "_")[[1]][1]
}

# AUXILIARY FUNCTION TO EXTRACT THE CBR TYPE (Bayes/FC)
get_cbr_type <- function(method_name) {
  str_split(method_name, "_")[[1]][2]
}

# FUNCTION TO CLASSIFY THE COMPARISON TYPE
get_comparison_type <- function(method1, method2, methods_FC_list, methods_Bayes_list) {
  is_m1_fc <- method1 %in% methods_FC_list
  is_m1_bayes <- method1 %in% methods_Bayes_list
  is_m2_fc <- method2 %in% methods_FC_list
  is_m2_bayes <- method2 %in% methods_Bayes_list
  
  htm1 <- get_htm_name(method1)
  htm2 <- get_htm_name(method2)
  
  # Intra-HTM_FC_CBR: Comparisons between different HTMs where the CBR was consistently Fold Change-based
  if (is_m1_fc && is_m2_fc) {
    return("Intra-HTM_FC_CBR")
  }
  # Intra-HTM_Bayes_CBR: Comparisons between different HTMs where the CBR was consistently Bayesian posterior probability-based
  else if (is_m1_bayes && is_m2_bayes) {
    return("Intra-HTM_Bayes_CBR")
  }
  # Intra-CBR_Fixed_HTM: Comparisons between the two different CBRs (FC vs Bayes) where the HTM was kept constant
  else if ((is_m1_fc && is_m2_bayes || is_m1_bayes && is_m2_fc) && (htm1 == htm2)) {
    return("Intra-CBR_Fixed_HTM")
  }
  # Inter-HTM_Inter-CBR: Comparisons between combinations where both the HTM and the CBR differed
  else if ((is_m1_fc && is_m2_bayes || is_m1_bayes && is_m2_fc) && (htm1 != htm2)) {
    return("Inter-HTM_Inter-CBR")
  }
  # Any other unclassified combination
  else {
    return("Unknown_Comparison")
  }
}

# AUXILIARY FUNCTION TO CALCULATE JACCARD INDEX
calculate_jaccard_index <- function(set1, set2) {
  if (length(set1) == 0 && length(set2) == 0) {
    return(0)
  }
  
  intersection_size <- length(intersect(set1, set2))
  union_size <- length(union(set1, set2))
  
  if (union_size == 0) {
    return(0)
  } else {
    return(intersection_size / union_size)
  }
}

# AUXILIARY FUNCTION TO CALCULATE EUCLIDEAN DISTANCE AND TRANSFORM IT INTO SIMILARITY
calculate_euclidean_similarity <- function(vec1, vec2) {
  # Ensure vectors have the same length and contain only numeric values
  if (length(vec1) != length(vec2) || !is.numeric(vec1) || !is.numeric(vec2)) {
    stop("Vectors for Euclidean distance must be numeric and have the same length.")
  }
  distance <- dist(rbind(vec1, vec2), method = "euclidean")
  # Transform distance to similarity (0 to 1). Distance 0 -> Similarity 1. Infinite distance -> Similarity 0.
  similarity <- 1 / (1 + as.numeric(distance))
  return(similarity)
}


# FUNCTION TO CONSOLIDATE INDIVIDUAL CLUEGO RESULTS (.xls) INTO A SINGLE TSV PER WORK AND DIRECTION
consolidate_cluego_results <- function(base_input_dir, output_tsv_dir, htms, cbrs, all_expected_method_names, works_list) {
  cat("\n--- INITIATING CLUEGO (.xls) FILE CONSOLIDATION ---\n")
  
  # Ensure the output directory for consolidated TSVs exists
  if (!dir.exists(output_tsv_dir)) {
    dir.create(output_tsv_dir, recursive = TRUE)
    cat(paste("Directory for consolidated TSVs created at:", output_tsv_dir, "\n"))
  }
  
  for (work_name in works_list) {
    for (direction_label in c("up", "down")) {
      cat(paste0("\nConsolidating ", work_name, " - Direction: ", direction_label, "...\n"))
      
      # Initialize an empty dataframe to consolidate results for this work and direction
      consolidated_df <- tibble(
        Ontology = character(),
        Term = character()
      )
      
      # Loop for each HTM and CBR combination
      for (htm in htms) {
        for (cbr in cbrs) {
          method_col_name <- paste0(htm, "_", cbr)
          
          # The "bayes_FC" methods do not exist in the user's classification.
          # We ignore the "bayes_FC" combination to avoid searching for a non-existent file.
          if (htm == "bayes" && cbr == "FC") {
            next
          }
          
          # Construct the expected file name. Ensure it matches your files.
          file_name <- paste0(work_name, "_", htm, "_", cbr, "_ClueGO_", direction_label, ".xls")
          file_path <- file.path(base_input_dir, file_name)
          
          if (file.exists(file_path)) {
            cat(paste0("  Reading: ", file_name, "\n"))
            df_current <- tryCatch({
              read_excel(file_path) %>%
                # Use "Ontology Source" to map to "Ontology"
                select(Term = "Term", Ontology = "Ontology Source", `Associated Genes` = "% Associated Genes") %>%
                # Convert to tibble for tidyverse compatibility
                as_tibble()
            }, error = function(e) {
              cat(paste("  WARNING: Could not read file", file_name, ":", e$message, ". It will be skipped.\n"))
              return(NULL)
            })
            
            if (!is.null(df_current) && nrow(df_current) > 0) {
              # NEW STEP: Group by Ontology and Term and calculate the mean of '% Associated Genes'
              # to handle potential duplicates within the same ClueGO file
              df_current <- df_current %>%
                group_by(Ontology, Term) %>%
                summarise(`Associated Genes` = mean(`Associated Genes`, na.rm = TRUE), .groups = 'drop')
              
              # Rename the value column to match the method name
              df_current <- df_current %>%
                rename(!!sym(method_col_name) := `Associated Genes`) %>%
                # Select only the necessary columns for joining
                select(Ontology, Term, !!sym(method_col_name))
              
              # Perform the join with the consolidated dataframe.
              # Use full_join to keep all terms and ontologies, filling with NA where no data exists.
              if (nrow(consolidated_df) == 0) {
                # If it's the first method, initialize the consolidated dataframe
                consolidated_df <- df_current
              } else {
                # If it's not the first method, join by Ontology and Term
                consolidated_df <- full_join(consolidated_df, df_current, by = c("Ontology", "Term"))
              }
            } else {
              cat(paste0("  INFO: File ", file_name, " exists but is empty or has no valid data. It will be treated as having no data.\n"))
            }
            
          } else {
            cat(paste0("  WARNING: File not found: ", file_name, ". Assuming no data for this method/filter.\n"))
          }
        } # End CBR loop
      } # End HTM loop
      
      # Fill NAs with 0 for methods that had no data (either because the file was not found or no enriched terms)
      # This is crucial so that 0 means "not enriched" in Jaccard calculation and for correlations.
      for (col_name in all_expected_method_names) {
        if (!col_name %in% colnames(consolidated_df)) {
          consolidated_df[[col_name]] <- 0
        }
        consolidated_df[[col_name]][is.na(consolidated_df[[col_name]])] <- 0
      }
      
      # Ensure columns are in the expected order (Ontology, Term, then methods)
      consolidated_df <- consolidated_df %>%
        select(Ontology, Term, all_of(all_expected_method_names))
      
      # Save the consolidated DataFrame in TSV format
      output_tsv_name <- paste0(work_name, "_0_Enrich_comp_results_", direction_label, "_all_methods.tsv")
      output_tsv_path <- file.path(output_tsv_dir, output_tsv_name)
      write_tsv(consolidated_df, output_tsv_path)
      cat(paste0("  Consolidated TSV saved for ", work_name, " (", direction_label, ") at: ", output_tsv_path, "\n"))
    } # End direction loop
  } # End work_name loop
  
  cat("\n--- CLUEGO (.xls) FILE CONSOLIDATION COMPLETED ---\n")
}


# --- 3. Main Function to Process a TSV File and Perform Analysis ---

process_consolidated_tsv_for_work_analysis <- function(
    tsv_file_path, work_name, direction_label,
    output_base_dir,
    all_expected_method_names, methods_FC_list, methods_Bayes_list
) {
  
  cat(paste0("\n--- Processing TSV file: ", basename(tsv_file_path), " (", work_name, ", ", direction_label, ") ---\n"))
  
  if (!file.exists(tsv_file_path)) {
    cat(paste("WARNING: TSV file not found:", tsv_file_path, ". Skipping.\n"))
    return(tibble()) # Returns an empty tibble if the file does not exist
  }
  
  df_consolidated <- tryCatch({
    read_tsv(tsv_file_path, show_col_types = FALSE) # show_col_types = FALSE to clean output
  }, error = function(e) {
    cat(paste("ERROR: Could not read TSV file", basename(tsv_file_path), ":", e$message, "\n"))
    return(NULL)
  })
  
  if (is.null(df_consolidated) || nrow(df_consolidated) == 0) {
    cat(paste("INFO: File", basename(tsv_file_path), "is empty or could not be processed. Skipping.\n"))
    return(tibble())
  }
  
  # Ensure method columns are numeric and handle NAs.
  # Also add columns with 0 if any expected method is not in the TSV.
  for (col in all_expected_method_names) {
    if (col %in% colnames(df_consolidated)) {
      df_consolidated[[col]] <- as.numeric(df_consolidated[[col]])
      df_consolidated[[col]][is.na(df_consolidated[[col]])] <- 0
    } else {
      df_consolidated[[col]] <- 0
      cat(paste0("INFO: Method column '", col, "' not found in TSV for ", work_name, " and was added with zeros.\n"))
    }
  }
  
  # --- Ontology-level Analysis and Metrics Calculation ---
  unique_ontologies <- unique(df_consolidated$Ontology)
  
  # Initialize a tibble to store all calculated metrics for this work/direction
  all_metrics_data_for_current_work_direction <- tibble(
    Work = character(),
    Ontology = character(),
    Direction = character(),
    Metric_Type = character(),
    Value = numeric(),
    Transformed_Value = numeric(), # For Jaccard (arcsin sqrt) and Euclidean (1/(1+d))
    Comparison_Type = character()
  )
  
  for (ontology_name_raw in unique_ontologies) {
    cat(paste0("  Calculating metrics for ontology: ", ontology_name_raw, "\n"))
    
    df_ontology <- df_consolidated %>% filter(Ontology == ontology_name_raw)
    
    # Extract enriched terms (genes or GO IDs) and associated genes (values) for each method
    # Terms with %Associated Genes > 0 are considered "enriched" for Jaccard.
    # All %Associated Genes values are used for Pearson/Spearman/Euclidean.
    method_data <- list()
    for (method_col in all_expected_method_names) {
      # Filter for terms enriched by this method (value > 0)
      enriched_terms <- df_ontology %>%
        filter(!!sym(method_col) > 0) %>%
        pull(Term) %>%
        unique() # Ensure unique terms
      method_data[[method_col]]$enriched_terms <- enriched_terms
      
      # Extract all %Associated Genes values for correlation/Euclidean
      method_data[[method_col]]$values <- df_ontology %>% pull(!!sym(method_col))
    }
    
    # --- Calculate Pairwise Metrics (Jaccard, Pearson, Spearman, Euclidean) ---
    methods_present_in_data <- all_expected_method_names[all_expected_method_names %in% colnames(df_ontology)]
    
    for (i in 1:length(methods_present_in_data)) {
      for (j in i:length(methods_present_in_data)) { # Only upper triangle including diagonal
        method1 <- methods_present_in_data[i]
        method2 <- methods_present_in_data[j]
        
        # Skip self-comparisons (Jaccard=1, Pearson/Spearman=1)
        if (i == j) {
          next
        }
        
        # Determine comparison type
        comp_type <- get_comparison_type(method1, method2, methods_FC_list, methods_Bayes_list)
        
        # Jaccard Index
        jaccard_val <- calculate_jaccard_index(method_data[[method1]]$enriched_terms, method_data[[method2]]$enriched_terms)
        jaccard_transformed <- asin(sqrt(jaccard_val))
        all_metrics_data_for_current_work_direction <- all_metrics_data_for_current_work_direction %>%
          add_row(
            Work = work_name, Ontology = ontology_name_raw, Direction = direction_label,
            Metric_Type = "Jaccard", Value = jaccard_val, Transformed_Value = jaccard_transformed,
            Comparison_Type = comp_type
          )
        
        # Pearson and Spearman Correlation
        # Ensure there's variance for correlation and at least 2 non-NA points
        if (sd(method_data[[method1]]$values, na.rm = TRUE) > 0 &&
            sd(method_data[[method2]]$values, na.rm = TRUE) > 0 &&
            sum(!is.na(method_data[[method1]]$values) & !is.na(method_data[[method2]]$values)) >= 2) {
          
          pearson_val <- cor(method_data[[method1]]$values, method_data[[method2]]$values, use = "pairwise.complete.obs", method = "pearson")
          spearman_val <- cor(method_data[[method1]]$values, method_data[[method2]]$values, use = "pairwise.complete.obs", method = "spearman")
          
          # Pearson and Spearman are already within [-1, 1], no further transformation for plots
          all_metrics_data_for_current_work_direction <- all_metrics_data_for_current_work_direction %>%
            add_row(
              Work = work_name, Ontology = ontology_name_raw, Direction = direction_label,
              Metric_Type = "Pearson", Value = pearson_val, Transformed_Value = pearson_val,
              Comparison_Type = comp_type
            ) %>%
            add_row(
              Work = work_name, Ontology = ontology_name_raw, Direction = direction_label,
              Metric_Type = "Spearman", Value = spearman_val, Transformed_Value = spearman_val,
              Comparison_Type = comp_type
            )
        } else {
          cat(paste0("    WARNING: Not enough variance or data points for Pearson/Spearman for ", method1, " vs ", method2, " in ", ontology_name_raw, ". Skipping correlations.\n"))
        }
        
        # Euclidean Similarity
        # Ensure at least 2 non-NA points for Euclidean distance
        if (sum(!is.na(method_data[[method1]]$values) & !is.na(method_data[[method2]]$values)) >= 2) {
          euclidean_val <- calculate_euclidean_similarity(method_data[[method1]]$values, method_data[[method2]]$values)
          # Euclidean similarity is already 0 to 1, but we use the "transformed" column for consistency in plots
          all_metrics_data_for_current_work_direction <- all_metrics_data_for_current_work_direction %>%
            add_row(
              Work = work_name, Ontology = ontology_name_raw, Direction = direction_label,
              Metric_Type = "Euclidean_Similarity", Value = euclidean_val, Transformed_Value = euclidean_val,
              Comparison_Type = comp_type
            )
        } else {
          cat(paste0("    WARNING: Not enough data points for Euclidean Similarity for ", method1, " vs ", method2, " in ", ontology_name_raw, ". Skipping Euclidean Similarity.\n"))
        }
        
      } # End inner method loop
    } # End outer method loop
  } # End ontology loop
  
  cat(paste0("--- Finished processing TSV file: ", basename(tsv_file_path), " ---\n"))
  return(all_metrics_data_for_current_work_direction)
}


# --- MAIN SCRIPT EXECUTION ---

# Create necessary output directories
if (!dir.exists(consolidated_tsvs_folder_path)) {
  dir.create(consolidated_tsvs_folder_path, recursive = TRUE)
}
if (!dir.exists(output_results_folder_path)) {
  dir.create(output_results_folder_path, recursive = TRUE)
}
if (!dir.exists(meta_analysis_results_folder_path)) {
  dir.create(meta_analysis_results_folder_path, recursive = TRUE)
  cat(paste("Meta-analysis results directory created at:", meta_analysis_results_folder_path, "\n"))
} else {
  cat(paste("Meta-analysis results directory already exists at:", meta_analysis_results_folder_path, "\n"))
}

# 1. Consolidate raw ClueGO .xls files into TSVs
consolidate_cluego_results(
  base_input_dir = base_analysis_path, # CORRECTED: Changed from cluego_raw_folder_path to base_analysis_path
  output_tsv_dir = consolidated_tsvs_folder_path,
  htms = htms,
  cbrs = cbrs,
  all_expected_method_names = all_expected_method_names,
  works_list = works_list
)


# 2. Process consolidated TSVs and collect all metrics data for meta-analysis
cat("\n--- COLLECTING ALL METRICS DATA FOR GLOBAL META-ANALYSIS ---\n")
all_jaccard_and_correlation_data <- tibble(
  Work = character(),
  Ontology = character(),
  Direction = character(),
  Metric_Type = character(),
  Value = numeric(),
  Transformed_Value = numeric(),
  Comparison_Type = character()
)

# Define which works and directions to process for meta-analysis (based on the original Jaccard meta-analysis)
# NOTE: This list should be defined based on the available consolidated TSV files and relevant works/directions.
# For simplicity, I'm assuming the same works/directions from your initial Jaccard meta-analysis.
# If you have more, add them here.
consolidated_files_to_process <- tribble(
  ~Work, ~Direction, ~FileSuffix,
  "W1", "up", "up_all_methods.tsv",
  "W1", "down", "down_all_methods.tsv", # Assuming W1 also has a DOWN direction, adjust if not
  "W3", "up", "up_all_methods.tsv", # W3 had 'ALL', assume 'up' or 'ALL' maps to a file. Adjust based on your consolidated filenames.
  "W3", "down", "down_all_methods.tsv", # Assuming W3 also has a DOWN direction, adjust if not
  "W4", "up", "up_all_methods.tsv",
  "W4", "down", "down_all_methods.tsv"
  # Add other relevant works/directions if you have consolidated TSVs for them
)

for (i in 1:nrow(consolidated_files_to_process)) {
  row_data <- consolidated_files_to_process[i,]
  current_tsv_path <- file.path(consolidated_tsvs_folder_path, paste0(row_data$Work, "_0_Enrich_comp_results_", row_data$FileSuffix))
  
  processed_work_data <- process_consolidated_tsv_for_work_analysis(
    tsv_file_path = current_tsv_path,
    work_name = row_data$Work,
    direction_label = row_data$Direction,
    output_base_dir = output_results_folder_path,
    all_expected_method_names = all_expected_method_names,
    methods_FC_list = methods_FC,
    methods_Bayes_list = methods_Bayes
  )
  
  all_jaccard_and_correlation_data <- bind_rows(all_jaccard_and_correlation_data, processed_work_data)
}

# Clean ontology names for plotting
all_jaccard_and_correlation_data <- all_jaccard_and_correlation_data %>%
  mutate(
    Ontology_Cleaned = case_when(
      str_detect(Ontology, "GO_BiologicalProcess") ~ "GO_BiologicalProcess",
      str_detect(Ontology, "GO_MolecularFunction") ~ "GO_MolecularFunction",
      str_detect(Ontology, "KEGG") ~ "KEGG",
      TRUE ~ "Other_Ontology" # For any other not mapped
    )
  )

cat(paste0("\n--- COLLECTION COMPLETE. Total of ", nrow(all_jaccard_and_correlation_data), " metric entries collected.---\n"))


# --- 4. GLOBAL ANALYSIS AND VISUALIZATION (META-ANALYSIS) ---

if (nrow(all_jaccard_and_correlation_data) == 0) {
  cat("\nWARNING: No data collected for meta-analysis. Statistical analysis and plotting cannot proceed.\n")
} else {
  
  # Define a consistent theme for all plots
  common_theme <- theme_minimal(base_size = 10) +
    theme(
      plot.title = element_blank(), # No individual plot titles (handled by patchwork tags and caption)
      axis.title = element_text(size = 10),
      panel.grid = element_blank(), # Remove all grid lines
      axis.line.y = element_line(colour = "black") # Black Y-axis line
    )
  
  # Define pairwise comparisons for ggpubr boxplots
  # This list might need adjustment based on the actual distribution of your Comparison_Type categories.
  # Ensure all categories in your `my_comparisons` list actually exist in `all_jaccard_and_correlation_data$Comparison_Type`.
  my_comparisons <- list(
    c("Intra-HTM_FC_CBR", "Intra-HTM_Bayes_CBR"),
    c("Intra-HTM_FC_CBR", "Intra-CBR_Fixed_HTM"),
    c("Intra-HTM_Bayes_CBR", "Intra-CBR_Fixed_HTM"),
    c("Intra-CBR_Fixed_HTM", "Inter-HTM_Inter-CBR")
  )
  
  unique_metric_types <- unique(all_jaccard_and_correlation_data$Metric_Type)
  
  # Loop through each metric type for analysis and plotting
  for (current_metric_type in unique_metric_types) {
    cat(paste0("\n--- Performing Meta-Analysis for Metric Type: ", current_metric_type, " ---\n"))
    
    data_for_metric <- all_jaccard_and_correlation_data %>%
      filter(Metric_Type == current_metric_type)
    
    # Ensure there's enough data for statistical tests for this metric type
    if (nrow(data_for_metric) == 0 || length(unique(data_for_metric$Comparison_Type)) < 2) {
      cat(paste0("  INFO: Not enough data or comparison types for ", current_metric_type, ". Skipping statistical analysis and plotting for this metric.\n"))
      next
    }
    
    # --- Global Statistical Tests (Kruskal-Wallis and Dunn's) ---
    cat(paste0("  Running Kruskal-Wallis test for ", current_metric_type, "...\n"))
    kruskal_result_global <- kruskal.test(Transformed_Value ~ Comparison_Type, data = data_for_metric)
    
    cat(paste0("    Kruskal-Wallis p-value for ", current_metric_type, ": ", kruskal_result_global$p.value, "\n"))
    
    dunn_summary_text <- ""
    if (kruskal_result_global$p.value < 0.05) {
      cat(paste0("  Kruskal-Wallis is significant (p < 0.05). Running Dunn's post-hoc test for ", current_metric_type, "...\n"))
      dunn_result_global <- dunn.test(x = data_for_metric$Transformed_Value,
                                      g = data_for_metric$Comparison_Type,
                                      method = "bonferroni",
                                      altp = TRUE)
      
      # Summarize significant pairs from Dunn's test
      sig_indices <- which(dunn_result_global$P.adjusted < 0.05)
      if (length(sig_indices) > 0) {
        significant_pairs <- paste(dunn_result_global$comparisons[sig_indices], collapse = "; ")
        dunn_summary_text <- paste0("Significant Dunn pairs: ", significant_pairs, "\n")
      } else {
        dunn_summary_text <- "No significant Dunn pairs after Bonferroni correction.\n"
      }
      cat(paste0("    ", dunn_summary_text))
    } else {
      dunn_summary_text <- "Kruskal-Wallis not significant, skipping Dunn's test.\n"
      cat(paste0("    ", dunn_summary_text))
    }
    
    # Save global statistical results to a text file
    stats_output_file <- file.path(meta_analysis_results_folder_path, paste0("global_stats_meta_analysis_", current_metric_type, ".txt"))
    
    sink(stats_output_file) # Redirect output to file
    cat(paste0("--- Global Statistical Analysis Results for ", current_metric_type, " ---\n\n"))
    cat("Kruskal-Wallis Test:\n")
    print(kruskal_result_global)
    cat("\n")
    cat(dunn_summary_text)
    sink() # Restore output to console
    cat(paste0("  Global statistical results saved to: ", stats_output_file, "\n"))
    
    
    # --- Plotting Figure X - Global Distribution and Comparison ---
    # Panel A: Histogram of Original Values (if applicable, Jaccard Index is 0-1, others -1 to 1)
    p_hist_orig <- ggplot(data_for_metric, aes(x = Value)) +
      geom_histogram(binwidth = 0.05, fill = "steelblue", color = "black", alpha = 0.7) +
      common_theme +
      labs(x = paste0(current_metric_type, " Value"), y = "Frequency") +
      theme(axis.line.x = element_line(colour = "black"))
    
    # Panel B: Histogram of Transformed Values (Jaccard_Transformed for Jaccard, Value for others)
    p_hist_trans <- ggplot(data_for_metric, aes(x = Transformed_Value)) +
      geom_histogram(binwidth = 0.05, fill = "darkgreen", color = "black", alpha = 0.7) +
      common_theme +
      labs(x = paste0(current_metric_type, " Value (Transformed)"), y = "Frequency") +
      theme(axis.line.x = element_line(colour = "black"))
    
    # Panel C: Boxplots by Comparison Type (Global)
    p_boxplot_global <- ggboxplot(data_for_metric, x = "Comparison_Type", y = "Transformed_Value",
                                  color = "Comparison_Type", palette = "jco",
                                  add = "jitter",
                                  ylab = paste0(current_metric_type, " Value (Transformed)"), xlab = "Comparison Type") +
      stat_compare_means(method = "kruskal.test", label.y = max(data_for_metric$Transformed_Value, na.rm = TRUE) * 1.05, size = 3) +
      stat_compare_means(comparisons = my_comparisons,
                         label = "p.signif", method = "wilcox.test", size = 3) + # Wilcoxon for pairwise in plot
      common_theme +
      theme(legend.position = "none",
            axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 8),
            axis.line.x = element_blank())
    
    # Combine panels for this metric's global figure
    fig_global <- (p_hist_orig + p_hist_trans) / p_boxplot_global +
      plot_annotation(title = paste0("Global Analysis: ", current_metric_type), tag_levels = 'A') &
      theme(plot.tag = element_text(size = 14, face = "bold"))
    
    # Save the global figure
    global_figure_name <- file.path(meta_analysis_results_folder_path, paste0("Figure_Global_", current_metric_type, ".png"))
    ggsave(global_figure_name, plot = fig_global, width = 190, height = 240, units = "mm", dpi = 600)
    cat(paste0("  Global analysis figure for ", current_metric_type, " saved to: ", global_figure_name, "\n"))
    
    
    # --- Plotting Figure X - By Ontology and Sensitivity Analysis ---
    
    # Panel A: Boxplots by Ontology (using facet_wrap)
    p_boxplot_ontology <- ggboxplot(data_for_metric, x = "Comparison_Type", y = "Transformed_Value",
                                    color = "Comparison_Type", palette = "jco",
                                    add = "jitter",
                                    ylab = paste0(current_metric_type, " Value (Transformed)"), xlab = "Comparison Type") +
      facet_wrap(~ Ontology_Cleaned, scales = "free_y", ncol = 3) +
      stat_compare_means(method = "kruskal.test",
                         label.y = max(data_for_metric$Transformed_Value, na.rm = TRUE) * 1.1, # Adjusted for per-facet max
                         size = 2.5) +
      stat_compare_means(comparisons = my_comparisons,
                         label = "p.signif", method = "wilcox.test", size = 2.5) +
      common_theme +
      theme(legend.position = "bottom",
            strip.text = element_text(size = 10, face = "bold"),
            axis.line.x = element_blank(),
            axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 7))
    
    
    # Panel B: Sensitivity Analysis (Kruskal-Wallis p-values excluding one work at a time)
    cat(paste0("\n--- INITIATING SENSITIVITY ANALYSIS for ", current_metric_type, " (EXCLUDING ONE WORK AT A TIME) ---\n"))
    
    unique_works_for_metric <- unique(data_for_metric$Work)
    sensitivity_results_df <- tibble(
      Excluded_Work = character(),
      Kruskal_p_value = numeric(),
      Dunn_Significant_Pairs_Summary = character()
    )
    
    for (excluded_work_id in unique_works_for_metric) {
      cat(paste0("  Performing sensitivity analysis excluding: ", excluded_work_id, " for ", current_metric_type, "\n"))
      data_subset_sens <- data_for_metric %>% filter(Work != excluded_work_id)
      
      # Ensure enough data points and comparison types remain for the test
      if (nrow(data_subset_sens) > 0 && length(unique(data_subset_sens$Comparison_Type)) > 1 && min(table(data_subset_sens$Comparison_Type)) >= 2) {
        kruskal_sens_result <- kruskal.test(Transformed_Value ~ Comparison_Type, data = data_subset_sens)
        
        significant_pairs_summary <- "Kruskal-Wallis not significant"
        if (kruskal_sens_result$p.value < 0.05) {
          dunn_sens_result <- dunn.test(x = data_subset_sens$Transformed_Value,
                                        g = data_subset_sens$Comparison_Type,
                                        method = "bonferroni",
                                        altp = TRUE)
          
          sig_indices <- which(dunn_sens_result$P.adjusted < 0.05)
          if (length(sig_indices) > 0) {
            significant_pairs_summary <- paste(dunn_sens_result$comparisons[sig_indices], collapse = "; ")
          } else {
            significant_pairs_summary <- "No significant Dunn pairs"
          }
        }
        
        sensitivity_results_df <- sensitivity_results_df %>%
          add_row(
            Excluded_Work = excluded_work_id,
            Kruskal_p_value = kruskal_sens_result$p.value,
            Dunn_Significant_Pairs_Summary = significant_pairs_summary
          )
      } else {
        cat(paste0("  INFO: Not enough data or groups for sensitivity analysis excluding '", excluded_work_id, "' for ", current_metric_type, ". Skipping.\n"))
        sensitivity_results_df <- sensitivity_results_df %>%
          add_row(
            Excluded_Work = excluded_work_id,
            Kruskal_p_value = NA,
            Dunn_Significant_Pairs_Summary = "Not enough data for analysis"
          )
      }
    }
    
    cat(paste0("\n--- SENSITIVITY ANALYSIS RESULTS for ", current_metric_type, " ---\n"))
    print(sensitivity_results_df)
    ruta_sensitivity_txt <- file.path(meta_analysis_results_folder_path, paste0("sensitivity_analysis_results_", current_metric_type, ".txt"))
    write_tsv(sensitivity_results_df, ruta_sensitivity_txt)
    cat(paste0("  Sensitivity analysis results saved to: ", ruta_sensitivity_txt, "\n"))
    cat(paste0("\n--- SENSITIVITY ANALYSIS COMPLETE for ", current_metric_type, " ---\n"))
    
    # Create a plot for Panel B: Sensitivity Analysis Summary (Kruskal-Wallis p-values)
    p_sens_analysis <- ggplot(sensitivity_results_df, aes(x = reorder(Excluded_Work, Kruskal_p_value), y = Kruskal_p_value)) +
      geom_col(fill = "lightblue", color = "black") +
      geom_hline(yintercept = 0.05, linetype = "dashed", color = "red", size = 0.5) +
      annotate("text", x = length(unique_works_for_metric) / 2, y = 0.06, label = "p = 0.05", color = "red", size = 3) +
      common_theme +
      labs(x = "Excluded Work", y = "Kruskal-Wallis P-value") +
      theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
            axis.line.x = element_line(colour = "black"))
    
    # Combine panels for this metric's ontology/sensitivity figure
    fig_ontology_sens <- p_boxplot_ontology / p_sens_analysis +
      plot_annotation(title = paste0("Ontology-specific and Sensitivity Analysis: ", current_metric_type), tag_levels = 'A') &
      theme(plot.tag = element_text(size = 14, face = "bold"))
    
    # Save the ontology and sensitivity figure
    ontology_sens_figure_name <- file.path(meta_analysis_results_folder_path, paste0("Figure_Ontology_Sensitivity_", current_metric_type, ".png"))
    ggsave(ontology_sens_figure_name, plot = fig_ontology_sens, width = 190, height = 240, units = "mm", dpi = 600)
    cat(paste0("  Ontology and sensitivity analysis figure for ", current_metric_type, " saved to: ", ontology_sens_figure_name, "\n"))
    
  } # End loop for current_metric_type
} # End if (nrow(all_jaccard_and_correlation_data) == 0)

cat("\n--- FULL META-ANALYSIS PROCESS COMPLETE --- \n")